{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_change(year):\n",
    "    '''\n",
    "    function to convert one and two digit years into four digits\n",
    "    '''\n",
    "    if len(year)==1:\n",
    "        year='200'+ year\n",
    "    else:\n",
    "        year='20'+year\n",
    "\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Vancouver Police Department's most recent data, available every Sunday.\n",
    "# this will be automated in the next iteration of this project\n",
    "df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/crime_csv_all_years.csv',parse_dates={'dttime':[1,2,3]}, keep_date_col=True)\n",
    "# dttime added for the next step which is gatherind day of the week data\n",
    "\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "df_temp=df.copy()\n",
    "\n",
    "# add day of the week to original data\n",
    "df_temp['day_of_week']=df_temp['dttime'].dt.weekday_name\n",
    "\n",
    "# remove missing data, all (or nearly all) of which is the non-property crime data\n",
    "# non-property crime data lacks all address information due to privacy concerns\n",
    "df2=df_temp.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# rename columns as all caps is tedious to work with\n",
    "df3=df2.rename(index=str, columns={\"YEAR\": \"year\", \"MONTH\": \"month\", \"DAY\":\"day\",\"HOUR\":\"hour\",\n",
    "                               \"MINUTE\":\"minute\", \"NEIGHBOURHOOD\":\"neighborhood\"})\n",
    "\n",
    "\n",
    "# sort by date\n",
    "df4=df3.sort_values(['year','month','day','hour','minute'])\n",
    "\n",
    "# remove extraneous data\n",
    "df5=df4.drop(['minute', 'HUNDRED_BLOCK','TYPE'], axis=1)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "df6=df5.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# bin by 1200am-1159am, 1200pm -1159pm\n",
    "hourbins = [-0.1,12.0,24.1]\n",
    "hourlabels = ['1200am-1159am', '1200pm-1159pm']\n",
    "# group by neighborhood, by day_segment\n",
    "df6['day_segment'] = pd.cut(df6[\"hour\"], bins=hourbins,labels=hourlabels)\n",
    "\n",
    "# remove extraneous data\n",
    "df7=df6[['year', 'month', 'day', 'day_of_week','day_segment', 'neighborhood']]\n",
    "\n",
    "# group by neighborhood, by day_segment\n",
    "df8=df7.groupby(df7.columns.tolist()).size()\n",
    "df9=pd.DataFrame(df8).reset_index()\n",
    "df10=df9.rename(index=str, columns={ 0 :\"number_of_crimes\"})\n",
    "# make final copy for merging\n",
    "\n",
    "# remove outlier of 499 crimes due to 2011 Stanley Cup riot\n",
    "df11=df10.loc[df10['number_of_crimes']!=df10['number_of_crimes'].max()]\n",
    "\n",
    "# remove second outlier of 104 crimes due to unknown reason\n",
    "df12=df11.loc[df11['number_of_crimes']!=df11['number_of_crimes'].max()]\n",
    "\n",
    "\n",
    "df_final=df12.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 560741 entries, 0 to 560740\n",
      "Data columns (total 11 columns):\n",
      "dttime           560741 non-null datetime64[ns]\n",
      "TYPE             560741 non-null object\n",
      "YEAR             560741 non-null object\n",
      "MONTH            560741 non-null object\n",
      "DAY              560741 non-null object\n",
      "HOUR             503868 non-null float64\n",
      "MINUTE           503868 non-null float64\n",
      "HUNDRED_BLOCK    560728 non-null object\n",
      "NEIGHBOURHOOD    501541 non-null object\n",
      "X                560741 non-null float64\n",
      "Y                560741 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(4), object(6)\n",
      "memory usage: 47.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/BA_weather_data.csv')\n",
    "\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "wdf2=wdf.copy()\n",
    "\n",
    "# remove extraneous data\n",
    "wdf3=wdf2[['DATE', 'TMAX', 'TMIN']]\n",
    "\n",
    "# rename columns as all caps is tedious to work with\n",
    "wdf4=wdf3.rename(index=str, columns={ \"DATE\":\"date\", \"TMAX\":\"tmax\",\"TMIN\":\"tmin\"})\n",
    "\n",
    "# extract data from wdf3 in a more usable form\n",
    "wdf4['year'] = wdf4.date.str.split('/').str.get(2)\n",
    "wdf4['month'] = wdf4.date.str.split('/').str.get(0)\n",
    "wdf4['day']=wdf4.date.str.split('/').str.get(1)\n",
    "wdf4=wdf4.drop('date', axis=1)\n",
    "# change year from 2 digits to 4 for merging\n",
    "wdf4.year='20'+ wdf4.year\n",
    "# change all possible values to numeric form\n",
    "wdf4=wdf4.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "wdf_final=wdf4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5606 entries, 0 to 5605\n",
      "Data columns (total 5 columns):\n",
      "STATION    5606 non-null object\n",
      "NAME       5606 non-null object\n",
      "DATE       5606 non-null object\n",
      "TMAX       5605 non-null float64\n",
      "TMIN       5605 non-null float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 219.1+ KB\n"
     ]
    }
   ],
   "source": [
    "wdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the consumer price index for Vancouver, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration\n",
    "cpi_df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/consumer_price_index_nohead.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "cpi_df2=cpi_df.copy()\n",
    "\n",
    "\n",
    "# extract data from cpi_df2 in a more usable form\n",
    "cpi_df2['year'] = cpi_df2.date.str.split('-').str.get(0)\n",
    "cpi_df2['month'] = cpi_df2.date.str.split('-').str.get(1)\n",
    "cpi_df2.drop('date', axis=1,inplace=True)\n",
    "cpi_df3=cpi_df2.copy()\n",
    "\n",
    "# change month from name to numeric\n",
    "import calendar\n",
    "d=dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
    "cpi_df3.month=cpi_df3.month.map(d)\n",
    "\n",
    "# change year from 1 or 2 digits to 4 for merging\n",
    "cpi_df3['year']=cpi_df3['year'].apply(year_change)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "cpi_df3=cpi_df3.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "cpi_df_final=cpi_df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186 entries, 0 to 185\n",
      "Data columns (total 2 columns):\n",
      "date                    186 non-null object\n",
      "consumer_price_index    186 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "cpi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unemployment data for British Columbia, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration\n",
    "emp_df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/employment_nohead.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "emp_df2=emp_df.copy()\n",
    "\n",
    "# extract data from cpi_df2 in a more usable form\n",
    "emp_df2['year'] = emp_df2.date.str.split('-').str.get(0)\n",
    "emp_df2['month'] = emp_df2.date.str.split('-').str.get(1)\n",
    "emp_df3=emp_df2.drop('date', axis=1)\n",
    "\n",
    "# change month from name to numeric\n",
    "import calendar\n",
    "d=dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
    "emp_df3.month=emp_df3.month.map(d)\n",
    "# change year from 1 or 2 digits to 4 for merging\n",
    "emp_df3['year']=emp_df3['year'].apply(year_change)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "emp_df4=emp_df3.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "emp_df_final=emp_df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186 entries, 0 to 185\n",
      "Data columns (total 3 columns):\n",
      "date                                186 non-null object\n",
      "seasonally_adjusted_unemployment    186 non-null float64\n",
      "unadjusted_unemployment             186 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 4.4+ KB\n"
     ]
    }
   ],
   "source": [
    "emp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the gross domestic product for British Columbia, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration and will be for Vancouver at best and British Columbia\n",
    "# if this is not possible\n",
    "gdp_df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/gdp_2007dollars_nohead.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "gdp_df2=gdp_df.copy()\n",
    "\n",
    "# extract data from cpi_df2 in a more usable form\n",
    "gdp_df2['year'] = gdp_df2.date.str.split('-').str.get(0)\n",
    "gdp_df2['month'] = gdp_df2.date.str.split('-').str.get(1)\n",
    "gdp_df3=gdp_df2.drop('date', axis=1)\n",
    "gdp_df4=gdp_df3.copy()\n",
    "\n",
    "# change month from name to numeric\n",
    "d=dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
    "gdp_df4.month=gdp_df4.month.map(d)\n",
    "# change year from 1 or 2 digits to 4 for merging\n",
    "gdp_df4['year']=gdp_df4['year'].apply(year_change)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "gdp_df5=gdp_df4.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "gdp_df_final=gdp_df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import drug posession data for British Columbia, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration\n",
    "drugs_df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/drug_offences_2006_to_2016.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "drugs_df2=drugs_df.copy()\n",
    "\n",
    "# remove extraneous data\n",
    "drugs_df3=drugs_df2[['year','Possession, cocaine ','Heroin, possession ',]]\n",
    "# make final copy to avoid slicing issues in Pandas\n",
    "drugs_df4=drugs_df3.copy()\n",
    "\n",
    "# insert row using means for 2017\n",
    "drugs_df4.loc[14]=[2017, drugs_df4['Possession, cocaine '].mean(),drugs_df4['Heroin, possession '].mean()]\n",
    "\n",
    "# insert row using means for 2018\n",
    "drugs_df4.loc[15]=[2018, drugs_df4['Possession, cocaine '].mean(),drugs_df4['Heroin, possession '].mean()]\n",
    "\n",
    "# make final copy for merging\n",
    "drugs_df_final=drugs_df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import annual heroin price data for Canada, gathered manually from various publications of the United Nations\n",
    "# this will be automated in the next iteration\n",
    "hp_df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/Heroin_Prices.csv')\n",
    "# make a copy of the original data to keep an original dataframe intacthp_df=pd.read_csv('data/Heroin_Prices.csv')\n",
    "hp_df2=hp_df.copy()\n",
    "\n",
    "# insert row using means for 2018\n",
    "hp_df2.loc[15]=[2018, hp_df2['Heroin Price Canada'].mean()]\n",
    "\n",
    "# make final copy for merging\n",
    "hp_df_final=hp_df2.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function that compiles all databases and also performs feature engineering\n",
    "'''\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df1=pd.merge(wdf_final,df_final, how='left', on=['year','month','day'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df2=pd.merge(new_df1,cpi_df_final, how='left', on=['year','month'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df3=pd.merge(new_df2,gdp_df_final, how='left', on=['year','month'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df4=pd.merge(new_df3,emp_df_final, how='left', on=['year','month'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df5=pd.merge(new_df4,drugs_df_final, how='left', on=['year'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df6=pd.merge(new_df5,hp_df_final, how='left', on=['year'])\n",
    "\n",
    "# change all possible values to numeric form\n",
    "new_df7=new_df6.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode day_segment and day_of_week for regession\n",
    "day_segment_number=['day_segment']\n",
    "day_of_week_number=['day_of_week']\n",
    "new_df8=pd.get_dummies(new_df7,columns=day_segment_number, drop_first=True)\n",
    "new_df9=pd.get_dummies(new_df8,columns=day_of_week_number,drop_first=True)\n",
    "new_df9.dropna()\n",
    "new_df10=new_df9.copy()\n",
    "# isolate the one high property crime neighborhood\n",
    "temp_cbd_df=new_df10[new_df10.neighborhood == \"Central Business District\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cbd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2_cbd_df=temp_cbd_df.drop(['neighborhood'],axis=1)\n",
    "temp3_cbd_df=temp2_cbd_df.dropna()\n",
    "cbd_df=temp3_cbd_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cbd_df[['tmax', 'tmin', 'year', 'month', 'day', \n",
    "       'consumer_price_index', 'gdp_millions_2007',\n",
    "       'seasonally_adjusted_unemployment', 'unadjusted_unemployment',\n",
    "       'Possession, cocaine ', 'Heroin, possession ', 'Heroin Price Canada',\n",
    "       'day_segment_1200pm-1159pm', 'day_of_week_Monday',\n",
    "       'day_of_week_Saturday', 'day_of_week_Sunday', 'day_of_week_Thursday',\n",
    "       'day_of_week_Tuesday', 'day_of_week_Wednesday']]\n",
    "\n",
    "y=cbd_df['number_of_crimes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # apply same transformation to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns=['tmax', 'tmin', 'year', 'month', 'day', \n",
    "       'consumer_price_index', 'gdp_millions_2007',\n",
    "       'seasonally_adjusted_unemployment', 'unadjusted_unemployment',\n",
    "       'Possession, cocaine ', 'Heroin, possession ', 'Heroin Price Canada',\n",
    "       'day_segment_1200pm-1159pm', 'day_of_week_Monday',\n",
    "       'day_of_week_Saturday', 'day_of_week_Sunday', 'day_of_week_Thursday',\n",
    "       'day_of_week_Tuesday', 'day_of_week_Wednesday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf=linear_model.Lasso(alpha=0.2)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df=pd.DataFrame(clf.coef_, X_columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1=clf.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions1))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions1))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions1)))\n",
    "print('R2 score: ',r2_score(y_test,predictions1))\n",
    "sns.distplot(y_test-predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regr=RandomForestRegressor(max_depth=2, random_state=42)\n",
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2=regr.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions2))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions2))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions2)))\n",
    "print('R2 score: ',r2_score(y_test,predictions2))\n",
    "sns.distplot(y_test-predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostRegressor()\n",
    "ada.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3=clf.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions3))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions3))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions3)))\n",
    "print('R2 score: ',r2_score(y_test,predictions3))\n",
    "sns.distplot(y_test-predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp=MLPRegressor()\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions4=clf.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions4))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions4))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions4)))\n",
    "print('R2 score: ',r2_score(y_test,predictions4))\n",
    "sns.distplot(y_test-predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "xgb=XGBRegressor()\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions5=xgb.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions5))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions5))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions5)))\n",
    "print('R2 score: ',r2_score(y_test,predictions5))\n",
    "sns.distplot(y_test-predictions5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# # A parameter grid for XGBoost\n",
    "# params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "# 'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}\n",
    "# # Initialize XGB and GridSearch\n",
    "# xgb = XGBRegressor(nthread=-1) \n",
    "\n",
    "# grid=GridSearchCV(xgb, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=-1, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "xgb2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions6=xgb2.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions6))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions6))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions6)))\n",
    "print('R2 score: ',r2_score(y_test,predictions6))\n",
    "sns.distplot(y_test-predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df2=pd.DataFrame(xgb2.feature_importances_, X_columns, columns=['Coefficient'])\n",
    "coeff_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
