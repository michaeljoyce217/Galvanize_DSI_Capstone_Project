{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_change(year):\n",
    "    '''\n",
    "    function to convert one and two digit years into four digits\n",
    "    '''\n",
    "    if len(year)==1:\n",
    "        year='200'+ year\n",
    "    else:\n",
    "        year='20'+year\n",
    "\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Vancouver Police Department's most recent data, available every Sunday.\n",
    "# this will be automated in the next iteration of this project\n",
    "df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/crime_csv_all_years.csv',parse_dates={'dttime':[1,2,3]}, keep_date_col=True)\n",
    "# dttime added for the next step which is gatherind day of the week data\n",
    "\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "df_temp=df.copy()\n",
    "\n",
    "# add day of the week to original data\n",
    "df_temp['day_of_week']=df_temp['dttime'].dt.weekday_name\n",
    "\n",
    "# remove missing data, all (or nearly all) of which is the non-property crime data\n",
    "# non-property crime data lacks all address information due to privacy concerns\n",
    "df2=df_temp.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# rename columns as all caps is tedious to work with\n",
    "df3=df2.rename(index=str, columns={\"YEAR\": \"year\", \"MONTH\": \"month\", \"DAY\":\"day\",\"HOUR\":\"hour\",\n",
    "                               \"MINUTE\":\"minute\", \"NEIGHBOURHOOD\":\"neighborhood\"})\n",
    "\n",
    "\n",
    "# sort by date\n",
    "df4=df3.sort_values(['year','month','day','hour','minute'])\n",
    "\n",
    "# remove extraneous data\n",
    "df5=df4.drop(['minute', 'HUNDRED_BLOCK','TYPE'], axis=1)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "df6=df5.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# bin by 1200am-1159am, 1200pm -1159pm\n",
    "hourbins = [-0.1,12.0,24.1]\n",
    "hourlabels = ['1200am-1159am', '1200pm-1159pm']\n",
    "# group by neighborhood, by day_segment\n",
    "df6['day_segment'] = pd.cut(df6[\"hour\"], bins=hourbins,labels=hourlabels)\n",
    "\n",
    "# remove extraneous data\n",
    "df7=df6[['year', 'month', 'day', 'day_of_week','day_segment', 'neighborhood']]\n",
    "\n",
    "# group by neighborhood, by day_segment\n",
    "df8=df7.groupby(df7.columns.tolist()).size()\n",
    "df9=pd.DataFrame(df8).reset_index()\n",
    "df10=df9.rename(index=str, columns={ 0 :\"number_of_crimes\"})\n",
    "# make final copy for merging\n",
    "\n",
    "# remove outlier of 499 crimes due to 2011 Stanley Cup riot\n",
    "df11=df10.loc[df10['number_of_crimes']!=df10['number_of_crimes'].max()]\n",
    "\n",
    "# remove second outlier of 104 crimes due to unknown reason\n",
    "df12=df11.loc[df11['number_of_crimes']!=df11['number_of_crimes'].max()]\n",
    "\n",
    "\n",
    "df_final=df12.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/BA_weather_data.csv')\n",
    "\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "wdf2=wdf.copy()\n",
    "\n",
    "# remove extraneous data\n",
    "wdf3=wdf2[['DATE', 'TMAX', 'TMIN']]\n",
    "\n",
    "# rename columns as all caps is tedious to work with\n",
    "wdf4=wdf3.rename(index=str, columns={ \"DATE\":\"date\", \"TMAX\":\"tmax\",\"TMIN\":\"tmin\"})\n",
    "\n",
    "# extract data from wdf3 in a more usable form\n",
    "wdf4['year'] = wdf4.date.str.split('/').str.get(2)\n",
    "wdf4['month'] = wdf4.date.str.split('/').str.get(0)\n",
    "wdf4['day']=wdf4.date.str.split('/').str.get(1)\n",
    "wdf4=wdf4.drop('date', axis=1)\n",
    "# change year from 2 digits to 4 for merging\n",
    "wdf4.year='20'+ wdf4.year\n",
    "# change all possible values to numeric form\n",
    "wdf4=wdf4.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "wdf_final=wdf4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/consumer_price_index_nohead.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f34813fd3e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# import the consumer price index for Vancouver, available monthly from Statistics Canada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# this will be automated in the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcpi_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/consumer_price_index_nohead.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# make a copy of the original data to keep an original dataframe intact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcpi_df2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpi_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/consumer_price_index_nohead.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# import the consumer price index for Vancouver, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration\n",
    "cpi_df=pd.read_csv('/Users/michaeljoyce/Desktop/Capstone/data/consumer_price_index_nohead.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "cpi_df2=cpi_df.copy()\n",
    "\n",
    "# import the consumer price index for Vancouver, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration\n",
    "cpi_df=pd.read_csv('data/consumer_price_index_nohead.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "cpi_df2=cpi_df.copy()\n",
    "\n",
    "# extract data from cpi_df2 in a more usable form\n",
    "cpi_df2['year'] = cpi_df2.date.str.split('-').str.get(0)\n",
    "cpi_df2['month'] = cpi_df2.date.str.split('-').str.get(1)\n",
    "cpi_df2.drop('date', axis=1,inplace=True)\n",
    "cpi_df3=cpi_df2.copy()\n",
    "\n",
    "# change month from name to numeric\n",
    "import calendar\n",
    "d=dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
    "cpi_df3.month=cpi_df3.month.map(d)\n",
    "\n",
    "# change year from 1 or 2 digits to 4 for merging\n",
    "cpi_df3['year']=cpi_df3['year'].apply(year_change)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "cpi_df3=cpi_df3.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "cpi_df_final=cpi_df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unemployment data for British Columbia, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration\n",
    "emp_df=pd.read_csv('data/employment_nohead.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "emp_df2=emp_df.copy()\n",
    "\n",
    "# extract data from cpi_df2 in a more usable form\n",
    "emp_df2['year'] = emp_df2.date.str.split('-').str.get(0)\n",
    "emp_df2['month'] = emp_df2.date.str.split('-').str.get(1)\n",
    "emp_df3=emp_df2.drop('date', axis=1)\n",
    "\n",
    "# change month from name to numeric\n",
    "import calendar\n",
    "d=dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
    "emp_df3.month=emp_df3.month.map(d)\n",
    "# change year from 1 or 2 digits to 4 for merging\n",
    "emp_df3['year']=emp_df3['year'].apply(year_change)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "emp_df4=emp_df3.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "emp_df_final=emp_df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the gross domestic product for British Columbia, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration and will be for Vancouver at best and British Columbia\n",
    "# if this is not possible\n",
    "gdp_df=pd.read_csv('data/gdp_2007dollars_nohead.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "gdp_df2=gdp_df.copy()\n",
    "\n",
    "# extract data from cpi_df2 in a more usable form\n",
    "gdp_df2['year'] = gdp_df2.date.str.split('-').str.get(0)\n",
    "gdp_df2['month'] = gdp_df2.date.str.split('-').str.get(1)\n",
    "gdp_df3=gdp_df2.drop('date', axis=1)\n",
    "gdp_df4=gdp_df3.copy()\n",
    "\n",
    "# change month from name to numeric\n",
    "d=dict((v,k) for k,v in enumerate(calendar.month_abbr))\n",
    "gdp_df4.month=gdp_df4.month.map(d)\n",
    "# change year from 1 or 2 digits to 4 for merging\n",
    "gdp_df4['year']=gdp_df4['year'].apply(year_change)\n",
    "\n",
    "# change all possible values to numeric form\n",
    "gdp_df5=gdp_df4.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# make final copy for merging\n",
    "gdp_df_final=gdp_df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import drug posession data for British Columbia, available monthly from Statistics Canada\n",
    "# this will be automated in the next iteration\n",
    "drugs_df=pd.read_csv('data/drug_offences_2006_to_2016.csv')\n",
    "# make a copy of the original data to keep an original dataframe intact\n",
    "drugs_df2=drugs_df.copy()\n",
    "\n",
    "# remove extraneous data\n",
    "drugs_df3=drugs_df2[['year','Possession, cocaine ','Heroin, possession ',]]\n",
    "# make final copy to avoid slicing issues in Pandas\n",
    "drugs_df4=drugs_df3.copy()\n",
    "\n",
    "# insert row using means for 2017\n",
    "drugs_df4.loc[14]=[2017, drugs_df4['Possession, cocaine '].mean(),drugs_df4['Heroin, possession '].mean()]\n",
    "\n",
    "# insert row using means for 2018\n",
    "drugs_df4.loc[15]=[2018, drugs_df4['Possession, cocaine '].mean(),drugs_df4['Heroin, possession '].mean()]\n",
    "\n",
    "# make final copy for merging\n",
    "drugs_df_final=drugs_df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import annual heroin price data for Canada, gathered manually from various publications of the United Nations\n",
    "# this will be automated in the next iteration\n",
    "hp_df=pd.read_csv('data/Heroin_Prices.csv')\n",
    "# make a copy of the original data to keep an original dataframe intacthp_df=pd.read_csv('data/Heroin_Prices.csv')\n",
    "hp_df2=hp_df.copy()\n",
    "\n",
    "# insert row using means for 2018\n",
    "hp_df2.loc[15]=[2018, hp_df2['Heroin Price Canada'].mean()]\n",
    "\n",
    "# make final copy for merging\n",
    "hp_df_final=hp_df2.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function that compiles all databases and also performs feature engineering\n",
    "'''\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df1=pd.merge(wdf_final,df_final, how='left', on=['year','month','day'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df2=pd.merge(new_df1,cpi_df_final, how='left', on=['year','month'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df3=pd.merge(new_df2,gdp_df_final, how='left', on=['year','month'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df4=pd.merge(new_df3,emp_df_final, how='left', on=['year','month'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df5=pd.merge(new_df4,drugs_df_final, how='left', on=['year'])\n",
    "\n",
    "\n",
    "\n",
    "# merge exisitng dataframes\n",
    "new_df6=pd.merge(new_df5,hp_df_final, how='left', on=['year'])\n",
    "\n",
    "# change all possible values to numeric form\n",
    "new_df7=new_df6.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=new_df_final[['year', 'month', 'day', 'tmax', 'tmin', 'precipitation',\n",
    "       'consumer_price_index', 'gdp_millions_2007',\n",
    "       'seasonally_adjusted_unemployment', 'unadjusted_unemployment',\n",
    "       'Possession, cocaine ', 'Heroin, possession ', 'Average_Heroin4_Price',\n",
    "       'day_segment_1200pm-1159pm', 'day_of_week_Monday',\n",
    "       'day_of_week_Saturday', 'day_of_week_Sunday', 'day_of_week_Thursday',\n",
    "       'day_of_week_Tuesday', 'day_of_week_Wednesday']]\n",
    "\n",
    "y_train=new_df_final['number_of_crimes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # apply same transformation to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(new_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = new_df_final.corr()\n",
    "#sns.heatmap(corr, \n",
    "            #xticklabels=corr.columns.values,\n",
    "            #yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.scatter_matrix(new_df_final, alpha = 0.3, figsize = (14,8), diagonal = 'kde');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeff_df=pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\n",
    "# coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predictions=lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf=linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df=pd.DataFrame(clf.coef_, X_columns, columns=['Coefficeient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions2))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions2))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regr=RandomForestRegressor(max_depth=2, random_state=42)\n",
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions3))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions3))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# param_dist = {\"n_estimators\":[10, 25, 50, 100],\n",
    "#               \"max_depth\": [2, 5, 10, 30, 50],\n",
    "#               \"max_features\": [3,4,5]}\n",
    "              \n",
    "# grid=GridSearchCV(regr,param_dist)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "predictions4 = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions4))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions4))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# param_dist = {\"n_estimators\":[10, 25, 50, 100,200,500],\n",
    "#               \"max_depth\": [2,3,4,5, 10, 25, 50, 100],\n",
    "#               \"max_features\": [3,4,5,7, 10,20]}\n",
    "              \n",
    "# grid=GridSearchCV(regr,param_dist)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator5=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator5.fit(X_train, y_train)\n",
    "\n",
    "predictions5 = estimator5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions5))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions5))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada=AdaBoostRegressor()\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# param_dist = {\"n_estimators\":[10, 25, 50, 100],\n",
    "#               \"learning_rate\": [1,0.5,0.1,0.05,0.01],\n",
    "#               \"random_state\": [42]}\n",
    "              \n",
    "# grid=GridSearchCV(ada,param_dist)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator6=AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
    "         n_estimators=50, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator6.fit(X_train, y_train)\n",
    "\n",
    "predictions6 = estimator6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions6))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions6))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr=SGDRegressor(shuffle=True)\n",
    "sgdr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions7=sgdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions7))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions7))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# param_dist = {\"alpha\":[0.01,0.001,0.001],\n",
    "#               'epsilon':[0.2,0.1,0.05,0.01],\n",
    "#               \"loss\": ['squared_loss','huber','epsilon_insensitive'],\n",
    "#               \"penalty\": ['l2','l1','elasticnet'],\n",
    "#              \"average\":[True, False]}\n",
    "              \n",
    "# grid=GridSearchCV(sgdr,param_dist)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator8=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
    "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
    "       loss='squared_loss', max_iter=None, n_iter=None, penalty='l2',\n",
    "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
    "       warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator8.fit(X_train, y_train)\n",
    "\n",
    "predictions8 = estimator8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions8))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions8))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elan=ElasticNetCV(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elan.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions9=elan.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions9))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions9))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = BayesianRidge(normalize=False)\n",
    "br.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions10=br.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions10))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions10))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "# br = BayesianRidge(normalize=False)\n",
    "\n",
    "# param_dist = {\"n_iter\":[100,300,500,1000]}\n",
    "              \n",
    "# grid=GridSearchCV(sgdr,param_dist)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator11=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
    "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
    "       loss='squared_loss', max_iter=None, n_iter=None, penalty='l2',\n",
    "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
    "       warm_start=False)\n",
    "\n",
    "estimator11.fit(X_train, y_train)\n",
    "\n",
    "predictions11 = estimator11.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions11))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions11))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.distplot(y_test-predictions11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagreg=BaggingRegressor()\n",
    "bagreg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions12=bagreg.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions12))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions12))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr=GradientBoostingRegressor()\n",
    "gbr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions13=gbr.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions13))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions13))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "              \n",
    "# grid=GridSearchCV(gbr, {\"max_depth\":[2,4,6,8,10],\n",
    "#               'n_estimators':[50,100,200]},\n",
    "#               verbose=1)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "xgb=XGBRegressor()\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions14=xgb.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions14))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions14))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df2=pd.DataFrame(xgb.feature_importances_, X_columns, columns=['Coefficient'])\n",
    "coeff_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "              \n",
    "# grid=GridSearchCV(xgb, {\"max_depth\":[2,4,6,8,10],\n",
    "#               'n_estimators':[50,100,200]},\n",
    "#               verbose=1)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator15=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "estimator15.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions15=estimator15.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions15))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions15))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df3=pd.DataFrame(estimator15.feature_importances_, X_columns, columns=['Coefficient'])\n",
    "coeff_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp=MLPRegressor()\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions16=mlp.predict(X_test)\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions16))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions16))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,predictions16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test-predictions16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
